---
title: "Untitled"
format: html
editor: visual
---

## Packages

```{r}
library(tidyverse)
library(haven)
library(readxl)
library(mice)
```

# Loading databases

```{r}

# Main database
# data <- read_dta("ZA7575.dta")
data <- read_dta("Data/ZA7575.dta")

# LGBTphobia database
ilga <- read_xlsx("ilga.xlsx", sheet = 2)
ilga <- ilga |> 
  filter(CONTINENT == "EUROPE")

# GINI index database
gini <- read_csv("eu_gini_coef.csv")

```

### Merging together Countries database

```{r}

names <- data.frame(
  COUNTRY = c(
    "Belgium", "Greece", "Lithuania", "Portugal", "Bulgaria", "Spain", "Luxembourg", "Romania", "Czechia", "France", 
    "Hungary", "Slovenia", "Denmark", "Croatia", "Malta", "Slovakia", "Germany", "Italy", "Netherlands", "Finland", "Estonia", "Cyprus", "Austria", "Sweden", "Ireland", "Latvia", "Poland",  "Iceland", "Norway", "Liechtenstein", "Switzerland",
  "Bosnia and Herzegovina", "Montenegro", "Moldova", "North Macedonia", "Georgia", "Albania", "Serbia", "Türkiye", 
    "Ukraine","Kosovo"
  ),
  geo = c(
    "BE", "EL", "LT", "PT", "BG", "ES", "LU", "RO", "CZ", "FR", "HU", "SI", "DK", "HR", "MT", "SK", "DE", "IT", "NL", "FI", "EE", "CY", "AT", "SE", "IE", "LV", "PL", "IS", "NO", "LI", "CH", "BA", "ME", "MD", "MK", "GE", "AL", "RS", "TR", "UA","XK"
  )
)

gini <- gini |> 
  select(geo, TIME_PERIOD, OBS_VALUE, OBS_FLAG) |> 
    filter(TIME_PERIOD == "2019") |> 
  left_join(names, by = "geo")


countries <- gini |> 
  left_join(ilga, by = "COUNTRY") |> 
  select(-TIME_PERIOD, CONTINENT) |> 
  filter(!is.na(CONTINENT))
```

## Selecting variables in the main dataset

```{r}

selected_data <- data |> 
  select(
    uniqid, 
    isocntry, # nationality keep 
    d11, # age  
    d70, # life satisfaction -recode below DK == NA
    polintr, # political interest -recode below DK == NA
    qa1, # globalization scale 1-4, convert 5 to NA 
    # qa5a,
    # qa7,
    # qa8,
    # qa9,
    # qa11,
    # qa12,
    # qa13,
    # qa14,
    # qa17,
    sd1_7, # do you know someone who is transgender. 
    # sd2_1, sd2_2, sd2_3, sd2_4, sd2_5, sd2_6, sd2_7, sd2_8,
    sd3,
    qc1_4, 
    qc2_1:qc2_14, # recode to 1 for discrimination == yes
      qc2_15, # recode to 0. discriminatino == no
      qc2_16, # recode to NA, impute missing data.  DONT KNOW
    # qc3,
    # qc4,
    qc6_1:qc6_11, # calculate average in new variable. not including values of 11 or 12
    qc7,
    qc8,
    qc9_1:qc9_11,
    qc10,
    qc11_1:qc1_10,
    qc12_1r, qc12_2r, qc12_3r, qc12_4r, qc12_5r, qc12_6r, qc12_7r, qc12_8r, qc12_9r, qc12_10r, qc12_11r, qc12_12r, qc12_13r, qc12_14r, qc12_15r,
    qc13_1r, qc13_2r, qc13_3r, qc13_4r, qc13_5r, qc13_6r, qc13_7r, qc13_8r, qc13_9r, qc13_10r, qc13_11r, qc13_12r, qc13_13r, qc13_14r, qc13_15r,
    qc15_1:qc15_3,
    qc17_1:qc17_7,
    qc18_1r, qc18_2r, qc18_3r,
    qc19, # TARGET VARIABLE 
    qc20,
    d1, # keep, scale from 0-10, remove 11, 12
    # d7,
    d10, # gender keep 
    d8, # keep education years 
    d15a, # convert to factor. occupation 
    d25, # keep type of city 
    # d40a, d40b, d40c, d43a, d43b,
    d60, # financial keep 
    d62_1,  # keep internet at home. calculate average 
    d63, # class keep. as factor 
    d72_1, d72_2, # keep. does my voice count
    p3r, # paradata
    p5, # paradata
    p4 # paradata
) 
```

### Feature engineering

```{r}
selected_data1 <- selected_data |> 
  rename(geo = isocntry) |> 
  left_join(names, by = "geo")
```

## Cleaning missing data

Regarding missing data, we drop out some variables for having too many NAs and impute the rest.

```{r, fig.height=6, fig.width=12}

imputed_data <- selected_data1 |> 
    mutate(d70 = ifelse(d70 == 5, NA, as.numeric(d70))) |> 
    mutate(qa1 = ifelse(qa1 == 5, NA, as.numeric(qa1))) |> 
    mutate(polintr = ifelse(polintr == 4, NA, as.numeric(polintr))) |> 
    mutate(d63 = ifelse(d63 == 5, NA, as.numeric(d63))) |> 
    mutate(d72_1 = ifelse(d72_1 == 4, NA, as.numeric(d72_1))) |> 
    mutate(d72_2 = ifelse(d72_2 == 4, NA, as.numeric(d72_2)))

imputed_data <- imputed_data |> select("d70", "qa1", "polintr", "d63", "d72_1", "d72_2")
init = mice(imputed_data)

meth = init$method

meth[c("d70", "qa1", "polintr", "d63", "d72_1", "d72_2")] <- "rf"

imputed_rf = mice(imputed_data, methid=meth, iterations = 10)

  
  imputed_data <- cbind(imputed_data, complete(imputed_rf))

  imputed_data <- imputed_data |> 
    select(-1, -2, -3, -4, -5, -6)
  

# Replace non imputed columns with imputed ones
imputed_vars <- names(imputed_data)

selected_data2 <- selected_data1[, !(names(selected_data1) %in% imputed_vars)]

selected_data3 <- cbind(selected_data2, imputed_data)

#colSums(is.na(selected_data3))
```

## Recode variables

```{r}
recoded_data <- selected_data3 |> 
      select(-qc3) |> 
  mutate(
    
    qc19 = factor(
      case_when(
        qc19 == 2 ~ 0, # make No as zero 
        qc19 == 3 ~ NA, # make DK as NA
        qc19 == 1 ~ 1 # keep Yes as 1        
        ),
      # label the values 
      labels = c("No", "Yes")
      ), 
    
    # qa1 = replace(qa1, qa1==5, NA),
    qc2_sum = qc2_1 + qc2_2 + qc2_3 + qc2_4 +
              qc2_5 + qc2_6 + qc2_7 + qc2_8 +
              qc2_9 + qc2_10 + qc2_11 + qc2_12 +
              qc2_13 + qc2_14,
    qc2_recode = case_when(
      qc2_sum > 0 ~ 1,
      qc2_15 == 1 ~ 0,
      qc2_16 == 1 ~ NA),
    # qc6_recode  = mean(qc6_1, qc6_2),
    d15a = factor(d15a, ordered = FALSE ),
    d1 = replace(d1, d1 %in% c(11,12), NA),
    d70 = factor(d70, ordered = F,
          labels = c("Very", "Somewhat", "Not very", "Not at all")), 
    polintr = factor(polintr, ordered = F,
          labels = c("frequently", "occasionally", "never"))) |> 
  select(
    -c(qc2_1:qc2_16)
  )

summary(recoded_data$d70)

```

## Descriptive

```{r}


ggplot(recoded_data) +
  geom_bar(aes(x = d70), fill = "blue") +
  labs(x = "Variable d70", y = "Frecuencia", title = "Gráfico de barras de la variable d70")
  

```

## Preliminary models

### Split training/testing data

```{r splitting, eval=FALSE}
library(caret)
# not sure if we need to split the data for surveys but anyway i will put it here just in case 
in.train <- createDataPartition(recoded_data$qc19, p = .7, list = F)
training.data <- recoded_data[in.train, ]
testing.data <- recoded_data[-in.train, ]
```

### Three binomial logistic models

According to all 3 models below, **life satisfaction** has a strong effect on an individual's opinion about transgender rights. The model results show that respondents who said that they are "not very" and "not at all" satisfied with their life are much more likely to answer "No" to the question about giving transgender people the right to change their civil documents. The coefficients show that both negative responses have a similar effect on the odds that they will answer Yes/No. Respondents who answered "somewhat satisfied" are also more likely to answer "No" but not by much.

Other predictors **Age**, **Political Interest**, and **Country** also show a strong effect on the outcome.

```{r models}

model1 <- glm(qc19 ~ d11 + d70*polintr,
             data = recoded_data, family = binomial)
model2 <- glm(qc19 ~ d11 + d70 + polintr, 
             data = recoded_data, family = binomial)
model3 <- glm(qc19 ~ COUNTRY + d70 -1,
              data = recoded_data, family = binomial)

stargazer::stargazer(model1, model2, model3, type = "text")
exp(model3$coefficients)
```

```{r}
new.data <- data.frame(d11 = c(20, 30, 40),
                       d70 = c("Very", "Very", "Very"),
                       polintr = c("frequently", "frequently", "frequently"))
predict.glm(model1, newdata = new.data, type = "response")
```

### Test data

With the threshold set at 50%, accuracy is only OK. Sensitivity is bad because there are lots of false positives. Most of the real "No"s are predicted as "Yes."

```{r eval=FALSE}
threshold = 0.5 # set the threshold here 
probabilities <- predict(model3, newdata = testing.data, type = "response")
predictions <- as.factor(ifelse(probabilities >= threshold, "Yes", "No"))

confusionMatrix(predictions, testing.data$qc19)
```

```{r eval=FALSE}
roc <- pROC::roc(testing.data$qc19, probabilities, na.rm = TRUE) 
sens <- roc$sensitivities #include sensitivities in test data
spec <- roc$specificities

plot(roc, col='green', print.thres=TRUE)
roc$levels

threshold = .602 # set the threshold here 
probabilities <- predict(model3, newdata = testing.data, type = "response")
predictions <- as.factor(ifelse(probabilities > threshold, "Yes", "No"))

confusionMatrix(predictions, testing.data$qc19)
```

### 
