---
title: "Untitled"
format: html
editor: visual
---

## Packages

```{r}
library(tidyverse)
library(haven)
library(readxl)
library(mice)
library(ggplot2)
library(gridExtra)
```

# Loading databases

```{r}

# Main database
# data <- read_dta("ZA7575.dta")
data <- read_dta("Data/ZA7575.dta")

# LGBTphobia database
ilga <- read_xlsx("ilga.xlsx", sheet = 2)
ilga <- ilga |> 
  filter(CONTINENT == "EUROPE")

# GINI index database
gini <- read_csv("eu_gini_coef.csv")

```

### Merging together Countries database

```{r}

names <- data.frame(
  COUNTRY = c(
    "Belgium", "Greece", "Lithuania", "Portugal", "Bulgaria", "Spain", "Luxembourg", "Romania", "Czechia", "France", 
    "Hungary", "Slovenia", "Denmark", "Croatia", "Malta", "Slovakia", "Germany", "Italy", "Netherlands", "Finland", "Estonia", "Cyprus", "Austria", "Sweden", "Ireland", "Latvia", "Poland",  "Iceland", "Norway", "Liechtenstein", "Switzerland",
  "Bosnia and Herzegovina", "Montenegro", "Moldova", "North Macedonia", "Georgia", "Albania", "Serbia", "Türkiye", 
    "Ukraine","Kosovo"
  ),
  geo = c(
    "BE", "EL", "LT", "PT", "BG", "ES", "LU", "RO", "CZ", "FR", "HU", "SI", "DK", "HR", "MT", "SK", "DE", "IT", "NL", "FI", "EE", "CY", "AT", "SE", "IE", "LV", "PL", "IS", "NO", "LI", "CH", "BA", "ME", "MD", "MK", "GE", "AL", "RS", "TR", "UA","XK"
  )
)

gini <- gini |> 
  select(geo, TIME_PERIOD, OBS_VALUE, OBS_FLAG) |> 
    filter(TIME_PERIOD == "2019") |> 
  left_join(names, by = "geo")


countries <- gini |> 
  left_join(ilga, by = "COUNTRY") |> 
  select(-TIME_PERIOD, CONTINENT) |> 
  filter(!is.na(CONTINENT))
```

## Selecting variables in the main dataset

```{r}
selected_data <- data |> 
  select(
    uniqid, 
    isocntry, # nationality keep 
    d11, # age  
    d70, # life satisfaction -recode below DK == NA
    polintr, # political interest -recode below DK == NA
    qa1, # globalization scale 1-4, convert 5 to NA 
    # qa5a,
    # qa7,
    # qa8,
    # qa9,
    # qa11,
    # qa12,
    # qa13,
    # qa14,
    # qa17,
    sd1_7, # do you know someone who is transgender. 
    # sd2_1, sd2_2, sd2_3, sd2_4, sd2_5, sd2_6, sd2_7, sd2_8,
    sd3,
    qc1_4, 
    qc2_1:qc2_14, # recode to 1 for discrimination == yes
      qc2_15, # recode to 0. discriminatino == no
      qc2_16, # recode to NA, impute missing data.  DONT KNOW
    # qc3,
    # qc4,
    qc6_1:qc6_11, # calculate average in new variable. not including values of 11 or 12
    qc7,
    qc8,
    qc9_1:qc9_11,
    qc10,
    qc11_1:qc1_10,
    qc12_1r, qc12_2r, qc12_3r, qc12_4r, qc12_5r, qc12_6r, qc12_7r, qc12_8r, qc12_9r, qc12_10r, qc12_11r, qc12_12r, qc12_13r, qc12_14r, qc12_15r,
    qc13_1r, qc13_2r, qc13_3r, qc13_4r, qc13_5r, qc13_6r, qc13_7r, qc13_8r, qc13_9r, qc13_10r, qc13_11r, qc13_12r, qc13_13r, qc13_14r, qc13_15r,
    qc15_1:qc15_3,
    qc17_1:qc17_7,
    qc18_1r, qc18_2r, qc18_3r,
    qc19, # TARGET VARIABLE 
    qc20,
    d1, # keep, scale from 0-10, remove 11, 12
    # d7,
    d10, # gender keep 
    d8, # keep education years 
    d15a, # convert to factor. occupation 
    d25, # keep type of city 
    # d40a, d40b, d40c, d43a, d43b,
    d60, # financial keep 
    d62_1,  # keep internet at home. calculate average 
    d63, # class keep. as factor 
    d72_1, d72_2, # keep. does my voice count
    p3r, # paradata
    p5, # paradata
    p4 # paradata
) 
```

### Feature engineering

```{r}

selected_data <- selected_data |> 
  rename(COUNTRY = isocntry) |> 
  left_join(names, by = "COUNTRY")

```

## Cleaning missing data

Regarding missing data, we drop out some variables for having too many NAs and impute the rest.

```{r, fig.height=6, fig.width=12}

imputed_data <- selected_data |> 
    mutate(d70 = ifelse(d70 == 5, NA, as.numeric(d70))) |> 
    mutate(qa1 = ifelse(qa1 == 5, NA, as.numeric(qa1))) |> 
    mutate(polintr = ifelse(polintr == 4, NA, as.numeric(polintr))) |> 
    mutate(d63 = ifelse(d63 == 5, NA, as.numeric(d63))) |> 
    mutate(d72_1 = ifelse(d72_1 == 4, NA, as.numeric(d72_1))) |> 
    mutate(d72_2 = ifelse(d72_2 == 4, NA, as.numeric(d72_2)))

imputed_data <- imputed_data |> select("d70", "qa1", "polintr", "d63", "d72_1", "d72_2")
init = mice(imputed_data)

meth = init$method

meth[c("d70", "qa1", "polintr", "d63", "d72_1", "d72_2")] <- "rf"

imputed_rf = mice(imputed_data, methid=meth, iterations = 10)

  
  imputed_data <- cbind(imputed_data, complete(imputed_rf))

  imputed_data <- imputed_data |> 
    select(-1, -2, -3, -4, -5, -6)
  

# Replace non imputed columns with imputed ones
imputed_vars <- names(imputed_data)

selected_data <- selected_data[, !(names(selected_data) %in% imputed_vars)]

selected_data <- cbind(selected_data, imputed_data)

colSums(is.na(selected_data))
```

## Recode variables

```{r}
recoded_data <- selected_data |> 
      select(-qc3) |> 
  mutate(
    
    qc19 = factor(
      case_when(
        qc19 == 2 ~ 0, # make No as zero 
        qc19 == 3 ~ NA, # make DK as NA
        qc19 == 1 ~ 1 # keep Yes as 1        
        ),
      # label the values 
      labels = c("No", "Yes")
      ), 
    
    qa1 = replace(qa1, qa1==5, NA),
    qc2_sum = qc2_1 + qc2_2 + qc2_3 + qc2_4 +
              qc2_5 + qc2_6 + qc2_7 + qc2_8 +
              qc2_9 + qc2_10 + qc2_11 + qc2_12 +
              qc2_13 + qc2_14,
    qc2_recode = case_when(
      qc2_sum > 0 ~ 1,
      qc2_15 == 1 ~ 0,
      qc2_16 == 1 ~ NA),
    # qc6_recode  = mean(qc6_1, qc6_2),
    d15a = factor(d15a, ordered = FALSE ),
    d1 = replace(d1, d1 %in% c(11,12), NA),
    d70 = factor(d70, ordered = F,
          labels = c("Very", "Somewhat", "Not very", "Not at all")), 
    polintr = factor(polintr, ordered = F,
          labels = c("frequently", "occasionally", "never"))) |> 
  select(
    -c(qc2_1:qc2_16)
  )

summary(recoded_data$d70)

```

## Descriptive

Most people answer "yes" to our target question (52.7%), but there are also a significant amount of 'no' (35%) and 'dont know' answers (11.9%).

```{r}
prop.table(table(recoded_data$qc19, useNA = "ifany")) * 100

```

Now, we will visualize some plots crossing the answers in QC19 to other variables.

-   d11 - Age. In younger ages more people tend to answer 'yes', which means, more people are in favor of allowing trans people to change their documents. As the age increases, the 'yes' answer is less likely, but still over 50%. The number of NAs also increase with age, with a peak between 60 and 70 years old.

-   sd3 - RECODE FIRST to remove NA and imppute. Religion. La mayoría de personas de la muestra se consideran católicas. De éstas, un 56% está a favor frente un 43% en contra. La identidad en la cual hay más personas en contra, con un 57%, es orthodox christian. In the other hand, there are more individuals who agree who are Agnostic and atheists.

-   polintr - Political interest. More people who never get involved in political topics answered 'don't know' proportionally than in the rest of categories. Thy're also the individuals with a higher rate of 'no' answers. There are more people who answer 'no' and have a frequent interest in politics compared to people who have an ocasional interest.

-   qa1 - RECODE FIRST to remove NA and imppute. Opinion on international trade. People who consider they benefit a lot from international trade allowed by the EU tend to be more positive regarding our target variable. However, as the perception of trade decreases, so does the amount of people who are in favor, as well as people who don't answer.

-   sd1_7 - RECODE FIRST to remove NA and imppute Friend/acquaintance who is trans. A 85.7% of europeans don't have a trans friend or aqcuaintance. However, from the people who don't know a trans person, 80% of them are in favor of trans people changing their document, a much higher percentage than the 57% between the people who do know a trans person.

-   qc2_recode - Suffered discrimination. Most people haven't suffered discrimination. The amount of people who is for and against the target question is very similar in both groups.

-   d25 - Type of city. RECODE FIRST to remove NA and imppute

-   d10 - Gender. More women than men answered 'yes' in the target variable.

-   d8 - Education years. RECODE FIRST to remove NA and imppute

```{r, fig.height=6, fig.width=12}

# d11 - Age
recoded_data$age_group <- cut(recoded_data$d11, breaks = seq(0, 100, by = 10), include.lowest = TRUE)

ggplot(recoded_data, aes(x = age_group, fill = qc19)) +
  geom_bar(position = "stack") +
    labs(x = "Edad", y = "Conteo", fill = "Variable qc19") +
  theme_minimal()

# sd3 - Religion
prop.table(table(recoded_data$sd3, recoded_data$qc19), margin = 1) * 100

# sd1_7 - Friend/acquintance who is trans
prop.table(table(recoded_data$sd1_7))
prop.table(table(recoded_data$sd1_7, recoded_data$qc19), margin = 1) * 100

# qc2_recode  - Experienced discrimination
prop.table(table(recoded_data$qc2_recode, recoded_data$qc19), margin = 1) * 100

variables <- c("polintr", "qa1", "d25", "d10", "d8")

colors <- c("cyan", "magenta", "yellow", "green", "orange", "purple")

# Lista para almacenar los gráficos
plots <- list()

# Generar gráficos para cada variable
for (variable in variables) {
  plot <- ggplot(recoded_data, aes_string(x = variable, fill = "qc19")) +
    geom_bar(position = "dodge") +
    labs(x = paste("Variable", variable), y = "Conteo", fill = "Variable cq19") +
    theme_minimal()
  plots[[variable]] <- plot
}

# Mostrar los gráficos en una cuadrícula
plot_grid(plotlist = plots, nrow = 3, ncol = 2)
  
```

## Preliminary models

### Split training/testing data

```{r splitting}
library(caret)
# not sure if we need to split the data for surveys but anyway i will put it here just in case 
in.train <- createDataPartition(recoded_data$qc19, p = .7, list = F)
training.data <- recoded_data[in.train, ]
testing.data <- recoded_data[-in.train, ]
```

### Three binomial logistic models

According to all 3 models below, **life satisfaction** has a strong effect on an individual's opinion about transgender rights. The model results show that respondents who said that they are "not very" and "not at all" satisfied with their life are much more likely to answer "No" to the question about giving transgender people the right to change their civil documents. The coefficients show that both negative responses have a similar effect on the odds that they will answer Yes/No. Respondents who answered "somewhat satisfied" are also more likely to answer "No" but not by much.

Other predictors **Age**, **Political Interest**, and **Country** also show a strong effect on the outcome.

```{r models}

model1 <- glm(qc19 ~ d11 + d70*polintr,
             data = training.data, family = binomial)
model2 <- glm(qc19 ~ d11 + d70 + polintr, 
             data = training.data, family = binomial)
model3 <- glm(qc19 ~ COUNTRY + d70 -1,
              data = training.data, family = binomial)

stargazer::stargazer(model1, model2, model3, type = "text")
exp(model3$coefficients)
```

```{r}
new.data <- data.frame(d11 = c(20, 30, 40),
                       d70 = c("Very", "Very", "Very"),
                       polintr = c("frequently", "frequently", "frequently"))
predict.glm(model1, newdata = new.data, type = "response")
```

### Test data

With the threshold set at 50%, accuracy is only OK. Sensitivity is bad because there are lots of false positives. Most of the real "No"s are predicted as "Yes."

```{r}
threshold = 0.5 # set the threshold here 
probabilities <- predict(model3, newdata = testing.data, type = "response")
predictions <- as.factor(ifelse(probabilities >= threshold, "Yes", "No"))

confusionMatrix(predictions, testing.data$qc19)
```

```{r}
roc <- pROC::roc(testing.data$qc19, probabilities, na.rm = TRUE) 
sens <- roc$sensitivities #include sensitivities in test data
spec <- roc$specificities

plot(roc, col='green', print.thres=TRUE)
roc$levels

threshold = .602 # set the threshold here 
probabilities <- predict(model3, newdata = testing.data, type = "response")
predictions <- as.factor(ifelse(probabilities > threshold, "Yes", "No"))

confusionMatrix(predictions, testing.data$qc19)
```
